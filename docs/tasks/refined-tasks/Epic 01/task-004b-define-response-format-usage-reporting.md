# Task 004.b: Define Response Format and Usage Reporting

**Priority:** P0 – Critical Path  
**Tier:** Core Infrastructure  
**Complexity:** 8 (Fibonacci points)  
**Phase:** Foundation  
**Dependencies:** Task 004, Task 004.a, Task 001, Task 002  

---

## Description

Task 004.b defines the canonical response format structures and usage reporting types that standardize how model inference results are represented throughout the Agentic Coding Bot (Acode) system. These types form the "output side" of the model provider interface, complementing the message and tool-call input types defined in Task 004.a. Consistent response formats are essential for downstream components to process inference results uniformly regardless of which provider (Ollama, vLLM) generated them.

The response format specification encompasses multiple distinct concerns: the primary ChatResponse record that wraps completion results, the streaming response infrastructure for real-time token delivery, the UsageInfo structure for token consumption tracking, and the metadata types that capture timing, provider information, and model identifiers. Each of these must be precisely defined to enable accurate billing simulation, performance monitoring, and conversation management across the application.

A critical aspect of this task is the streaming response architecture. Unlike simple request-response patterns, streaming completions deliver content incrementally as tokens are generated by the model. The Acode system MUST support streaming for responsive user experience while also supporting non-streaming mode for batch processing and testing scenarios. The streaming infrastructure includes delta types that represent partial content updates and accumulator utilities that merge deltas into complete responses.

Usage reporting serves multiple purposes in the Acode system even though no external billing occurs. Token counts enable: (1) conversation truncation decisions when context windows are exceeded, (2) performance analysis and optimization, (3) model selection based on capacity requirements, and (4) audit logging for operational analysis. The UsageInfo type MUST accurately capture prompt tokens, completion tokens, and optionally cached tokens for providers that support KV cache hit reporting.

Integration points span several task specifications. The ChatResponse type is returned by the IModelProvider.CompleteAsync method defined in Task 004, incorporating the message types from Task 004.a for the response content. The provider registry from Task 004.c uses response metadata to verify provider health and capabilities. The Ollama adapter (Task 005) and vLLM adapter (Task 006) both produce ChatResponse instances, normalizing their native formats. The conversation manager (referenced in later epics) consumes responses to maintain context.

Error handling within responses introduces additional complexity. A response can be successful but contain a refusal (model declined the request), successful but truncated (hit max tokens), or represent various partial failure states. The response format MUST distinguish these cases clearly so calling code can handle each appropriately. Error types include rate limiting (relevant for some local deployments), context overflow, model unavailability, and tool-call validation failures.

Performance considerations mandate efficient response handling. Large responses containing tool calls with substantial JSON arguments MUST NOT cause excessive memory allocation. Streaming responses MUST NOT buffer entire completions before delivery. The response types MUST support zero-copy access patterns where possible and provide clear ownership semantics for disposal of resources.

The specification MUST address serialization requirements comprehensively. Responses may be logged for audit purposes, cached for testing, or transmitted between process boundaries. JSON serialization MUST be efficient and compatible with the logging infrastructure defined in Task 003.c. Binary serialization options should be considered for inter-process communication performance.

Compatibility with provider-specific extensions presents design challenges. Different providers include varying metadata in their responses: model versions, quantization details, generation parameters used, and custom fields. The response format MUST provide an extensibility mechanism that preserves this information without polluting the core type with provider-specific fields. The metadata bag pattern allows capturing arbitrary provider extensions.

This task delivers the foundation for all inference result processing in the Acode system. Incomplete or ambiguous response format specification would cascade into bugs across the Ollama adapter, vLLM adapter, conversation manager, tool execution pipeline, and CLI output formatting. The comprehensive specification ensures consistent behavior and enables robust testing of downstream components.

---

## Glossary / Terms

| Term | Definition |
|------|------------|
| ChatResponse | Primary record encapsulating a complete model completion result |
| StreamingResponse | Async enumerable delivering partial response deltas as they arrive |
| ResponseDelta | Incremental update containing partial content or tool call fragments |
| UsageInfo | Token consumption metrics for an inference request |
| FinishReason | Enum indicating why generation stopped (complete, length, tool_call, etc.) |
| PromptTokens | Count of tokens in the input messages |
| CompletionTokens | Count of tokens in the generated response |
| CachedTokens | Count of tokens served from KV cache (provider-specific) |
| ResponseMetadata | Auxiliary information about the response (timing, model, provider) |
| ContentFilter | Moderation result indicating content safety status |
| Refusal | Response indicating model declined the request |
| StopReason | Specific condition that terminated generation |
| DeltaAccumulator | Utility that merges streaming deltas into complete response |
| TokenRate | Tokens per second measurement for performance tracking |
| ResponseBuilder | Mutable builder for constructing responses incrementally |
| ProviderExtensions | Dictionary containing provider-specific metadata fields |
| GenerationId | Unique identifier for a specific inference request/response pair |
| ModelSnapshot | Point-in-time identifier of exact model version used |
| Latency | Time elapsed from request submission to first/last token |
| TTFT | Time To First Token - critical streaming performance metric |
| TotalLatency | Time from request to complete response |
| StreamState | Current state of a streaming response (active, complete, error) |

---

## Out of Scope

The following items are explicitly excluded from Task 004.b:

- **Token counting implementation** - How tokens are counted is provider-specific (Task 005, Task 006)
- **Response caching logic** - Caching is an infrastructure concern for later tasks
- **Billing or cost calculation** - No external billing in Acode system
- **Response persistence** - Storage is handled by audit (Task 003.c) and conversation management
- **Content moderation rules** - ContentFilter reports status, doesn't define policies
- **Retry logic for failed responses** - Retry policies are in provider adapters
- **Response transformation for display** - CLI formatting is Task 010+
- **Response comparison or diffing** - Analysis utilities are separate tasks
- **Response compression** - Wire optimization is infrastructure-level concern
- **Multi-response aggregation** - Ensemble or voting patterns are not in scope
- **Response translation** - Localization is not addressed
- **Response watermarking** - Provenance marking is not required

---

## Functional Requirements

### ChatResponse Record

- FR-001: ChatResponse MUST be defined as an immutable record type in the Domain layer
- FR-002: ChatResponse MUST include an Id property as a unique response identifier (string, GUID format)
- FR-003: ChatResponse MUST include a Message property of type ChatMessage (from Task 004.a)
- FR-004: ChatResponse MUST include a FinishReason property indicating generation termination cause
- FR-005: ChatResponse MUST include a Usage property of type UsageInfo
- FR-006: ChatResponse MUST include a Metadata property of type ResponseMetadata
- FR-007: ChatResponse MUST include a Created timestamp (DateTimeOffset, UTC)
- FR-008: ChatResponse MUST include a Model property identifying the model that generated the response
- FR-009: ChatResponse MUST include an optional Refusal property for declined requests
- FR-010: ChatResponse MUST provide a bool IsComplete property (FinishReason == Stop)
- FR-011: ChatResponse MUST provide a bool IsTruncated property (FinishReason == Length)
- FR-012: ChatResponse MUST provide a bool HasToolCalls property (Message.ToolCalls != null && Count > 0)
- FR-013: ChatResponse MUST implement value equality comparing Id
- FR-014: ChatResponse MUST be serializable to JSON via System.Text.Json
- FR-015: ChatResponse MUST support null Refusal when request was not declined
- FR-016: ChatResponse MUST validate that Id is non-empty on construction
- FR-017: ChatResponse MUST validate that Message is not null on construction
- FR-018: ChatResponse MUST validate that FinishReason is a valid enum value

### FinishReason Enum

- FR-019: FinishReason MUST be defined as an enum in the Domain layer
- FR-020: FinishReason MUST include Stop value (normal completion)
- FR-021: FinishReason MUST include Length value (max tokens reached)
- FR-022: FinishReason MUST include ToolCalls value (generation stopped for tool execution)
- FR-023: FinishReason MUST include ContentFilter value (content moderation triggered)
- FR-024: FinishReason MUST include Error value (generation failed)
- FR-025: FinishReason MUST include Cancelled value (request was cancelled)
- FR-026: FinishReason MUST serialize to lowercase snake_case strings in JSON
- FR-027: FinishReason MUST deserialize case-insensitively
- FR-028: FinishReason MUST map from Ollama "done_reason" field
- FR-029: FinishReason MUST map from vLLM "finish_reason" field

### UsageInfo Record

- FR-030: UsageInfo MUST be defined as an immutable record type
- FR-031: UsageInfo MUST include PromptTokens property (int, non-negative)
- FR-032: UsageInfo MUST include CompletionTokens property (int, non-negative)
- FR-033: UsageInfo MUST include TotalTokens computed property (Prompt + Completion)
- FR-034: UsageInfo MUST include optional CachedTokens property (int?, non-negative when present)
- FR-035: UsageInfo MUST include optional ReasoningTokens property for models with CoT
- FR-036: UsageInfo MUST validate non-negative values on construction
- FR-037: UsageInfo MUST provide static Empty property returning zeros
- FR-038: UsageInfo MUST implement value equality on all token counts
- FR-039: UsageInfo MUST serialize to JSON matching OpenAI usage format
- FR-040: UsageInfo MUST provide Add method for combining usage across requests
- FR-041: UsageInfo MUST provide ToString showing "Prompt: X, Completion: Y, Total: Z"

### ResponseMetadata Record

- FR-042: ResponseMetadata MUST be defined as an immutable record type
- FR-043: ResponseMetadata MUST include ProviderId property (string, e.g., "ollama", "vllm")
- FR-044: ResponseMetadata MUST include ModelId property (string, exact model identifier)
- FR-045: ResponseMetadata MUST include RequestDuration property (TimeSpan)
- FR-046: ResponseMetadata MUST include TimeToFirstToken property (TimeSpan?, null for non-streaming)
- FR-047: ResponseMetadata MUST include TokensPerSecond computed property (CompletionTokens / Duration)
- FR-048: ResponseMetadata MUST include Extensions property (IReadOnlyDictionary<string, JsonElement>)
- FR-049: ResponseMetadata MUST preserve arbitrary provider-specific fields in Extensions
- FR-050: ResponseMetadata MUST support null TimeToFirstToken for non-streaming responses
- FR-051: ResponseMetadata MUST validate ProviderId is non-empty
- FR-052: ResponseMetadata MUST validate ModelId is non-empty
- FR-053: ResponseMetadata MUST validate RequestDuration is non-negative

### Streaming Response Types

- FR-054: StreamingChatResponse MUST be defined as IAsyncEnumerable<ResponseDelta>
- FR-055: StreamingChatResponse MUST support cancellation via CancellationToken
- FR-056: ResponseDelta MUST be defined as an immutable record type
- FR-057: ResponseDelta MUST include Index property (int, position in stream)
- FR-058: ResponseDelta MUST include optional ContentDelta property (string?)
- FR-059: ResponseDelta MUST include optional ToolCallDelta property (ToolCallDelta? from 004.a)
- FR-060: ResponseDelta MUST include optional FinishReason property (present only on final delta)
- FR-061: ResponseDelta MUST include optional Usage property (present only on final delta)
- FR-062: ResponseDelta MUST provide bool IsComplete property (FinishReason != null)
- FR-063: ResponseDelta MUST validate that at least ContentDelta or ToolCallDelta is present (or IsComplete)
- FR-064: StreamingChatResponse MUST propagate exceptions as async enumeration failures
- FR-065: StreamingChatResponse MUST support multiple simultaneous enumerators (replays from buffer)

### Delta Accumulator

- FR-066: DeltaAccumulator MUST be defined as a mutable class for building responses
- FR-067: DeltaAccumulator MUST provide Append(ResponseDelta) method
- FR-068: DeltaAccumulator MUST concatenate ContentDelta strings efficiently (StringBuilder)
- FR-069: DeltaAccumulator MUST merge ToolCallDelta by Index into complete ToolCalls
- FR-070: DeltaAccumulator MUST capture final FinishReason from last delta
- FR-071: DeltaAccumulator MUST capture final Usage from last delta
- FR-072: DeltaAccumulator MUST provide Build() returning complete ChatResponse
- FR-073: DeltaAccumulator MUST track TotalTokens across all deltas
- FR-074: DeltaAccumulator MUST track delta count for debugging
- FR-075: DeltaAccumulator MUST provide Current property for partial response access
- FR-076: DeltaAccumulator MUST be thread-safe for concurrent Append calls
- FR-077: DeltaAccumulator MUST throw if Build() called before final delta received

### Response Builder

- FR-078: ResponseBuilder MUST provide fluent API for constructing ChatResponse
- FR-079: ResponseBuilder MUST have WithId(string) method
- FR-080: ResponseBuilder MUST have WithMessage(ChatMessage) method
- FR-081: ResponseBuilder MUST have WithFinishReason(FinishReason) method
- FR-082: ResponseBuilder MUST have WithUsage(UsageInfo) method
- FR-083: ResponseBuilder MUST have WithMetadata(ResponseMetadata) method
- FR-084: ResponseBuilder MUST have WithRefusal(string?) method
- FR-085: ResponseBuilder MUST have Build() method returning validated ChatResponse
- FR-086: ResponseBuilder MUST generate Id if not explicitly provided (GUID)
- FR-087: ResponseBuilder MUST set Created timestamp automatically
- FR-088: ResponseBuilder MUST validate required fields on Build()

### Content Filter Type

- FR-089: ContentFilterResult MUST be defined as a record type
- FR-090: ContentFilterResult MUST include Category property (enum: Sexual, Violence, Hate, SelfHarm)
- FR-091: ContentFilterResult MUST include Severity property (enum: Safe, Low, Medium, High)
- FR-092: ContentFilterResult MUST include Filtered property (bool, true if content was blocked)
- FR-093: ContentFilterResult MUST include optional Reason property (string description)
- FR-094: ChatResponse MUST include optional ContentFilterResults (IReadOnlyList<ContentFilterResult>?)
- FR-095: ContentFilterResult MUST serialize to JSON in provider-agnostic format

### Error Response Handling

- FR-096: ChatResponse MUST distinguish successful vs error responses via FinishReason
- FR-097: Error responses MUST include error information in Refusal property
- FR-098: Error responses MUST have FinishReason.Error
- FR-099: Error responses MUST still include valid Metadata for timing analysis
- FR-100: Error responses MUST include Usage if tokens were consumed before failure

### Serialization

- FR-101: All response types MUST use System.Text.Json source generators
- FR-102: JSON property names MUST use snake_case for compatibility
- FR-103: Null properties MUST be omitted from JSON output
- FR-104: DateTimeOffset MUST serialize as ISO 8601 string
- FR-105: TimeSpan MUST serialize as floating-point seconds
- FR-106: Enum values MUST serialize as lowercase strings
- FR-107: Extensions dictionary MUST preserve original JSON structure
- FR-108: Deserialization MUST be lenient for unknown properties (ignore)
- FR-109: ResponseJsonContext MUST be defined for AOT compilation support

### Factory Methods

- FR-110: ChatResponse.Success MUST create successful response with Stop finish reason
- FR-111: ChatResponse.Truncated MUST create response with Length finish reason
- FR-112: ChatResponse.ToolCallsRequired MUST create response with ToolCalls finish reason
- FR-113: ChatResponse.Refused MUST create response with refusal message
- FR-114: ChatResponse.Error MUST create error response with description
- FR-115: ChatResponse.FromDelta MUST create response from accumulated deltas

---

## Non-Functional Requirements

### Performance

- NFR-001: ChatResponse construction MUST complete in < 5 microseconds
- NFR-002: UsageInfo construction MUST complete in < 1 microsecond
- NFR-003: ResponseDelta construction MUST complete in < 1 microsecond
- NFR-004: DeltaAccumulator.Append MUST complete in < 10 microseconds average
- NFR-005: DeltaAccumulator.Build MUST complete in < 100 microseconds
- NFR-006: JSON serialization of ChatResponse MUST complete in < 1 millisecond
- NFR-007: JSON deserialization of ChatResponse MUST complete in < 1 millisecond
- NFR-008: Memory allocation for ChatResponse MUST be < 2KB (excluding content)
- NFR-009: Streaming enumeration overhead MUST be < 5 microseconds per delta
- NFR-010: StringBuilder in DeltaAccumulator MUST grow efficiently (doubling strategy)
- NFR-011: No boxing of value types in response handling hot paths
- NFR-012: Response types MUST support struct-based iteration where applicable

### Reliability

- NFR-013: Response types MUST be immutable to prevent concurrent modification issues
- NFR-014: DeltaAccumulator MUST handle out-of-order deltas gracefully
- NFR-015: Streaming response MUST recover from transient enumeration failures
- NFR-016: Response validation MUST catch all invalid states at construction
- NFR-017: Extensions dictionary MUST not throw for missing keys (TryGetValue pattern)
- NFR-018: TTFB measurement MUST be accurate to millisecond precision

### Security

- NFR-019: Response content MUST be treated as untrusted data
- NFR-020: ToString() MUST NOT include full response content (truncate at 200 chars)
- NFR-021: Serialization MUST NOT include internal implementation details
- NFR-022: Extensions dictionary MUST NOT be modified after construction
- NFR-023: Error messages in Refusal MUST NOT expose sensitive system details

### Maintainability

- NFR-024: All response types MUST have complete XML documentation
- NFR-025: All public APIs MUST have unit test coverage > 95%
- NFR-026: Response types MUST follow Domain layer conventions
- NFR-027: Breaking changes to response format MUST be versioned
- NFR-028: Serialization format MUST be backward compatible across versions

### Compatibility

- NFR-029: Response format MUST be mappable from Ollama chat completion response
- NFR-030: Response format MUST be mappable from vLLM completion response
- NFR-031: Response format MUST support future provider additions
- NFR-032: JSON format MUST be parseable by external tools for debugging
- NFR-033: Response types MUST compile without warnings on .NET 8+

### Observability

- NFR-034: Response processing MUST emit structured log events
- NFR-035: Token counts MUST be available for metrics aggregation
- NFR-036: Timing information MUST support performance dashboarding
- NFR-037: Error responses MUST include correlation identifiers

---

## User Manual Documentation

### Overview

The response format types define how model inference results are represented in the Acode system. These types provide a unified interface for processing completions from any supported provider (Ollama, vLLM).

### Quick Start

#### Creating a Simple Response

```csharp
using AgenticCoder.Domain.Models;

// Using factory method
var response = ChatResponse.Success(
    message: ChatMessage.CreateAssistant("Hello! How can I help you?"),
    usage: new UsageInfo(PromptTokens: 10, CompletionTokens: 15),
    model: "llama3.2:8b"
);

// Check response properties
Console.WriteLine($"Response ID: {response.Id}");
Console.WriteLine($"Finish Reason: {response.FinishReason}");
Console.WriteLine($"Total Tokens: {response.Usage.TotalTokens}");
Console.WriteLine($"Tokens/sec: {response.Metadata.TokensPerSecond:F1}");
```

#### Handling Streaming Responses

```csharp
// Consuming a streaming response
IAsyncEnumerable<ResponseDelta> stream = await provider.StreamAsync(request);

var accumulator = new DeltaAccumulator();
await foreach (var delta in stream.WithCancellation(cancellationToken))
{
    accumulator.Append(delta);
    
    // Display incremental content
    if (delta.ContentDelta is not null)
    {
        Console.Write(delta.ContentDelta);
    }
    
    // Check for completion
    if (delta.IsComplete)
    {
        Console.WriteLine($"\n[Finished: {delta.FinishReason}]");
    }
}

// Get complete response
ChatResponse response = accumulator.Build();
```

### Response Types Reference

#### ChatResponse

The primary response type containing a complete model completion:

| Property | Type | Description |
|----------|------|-------------|
| Id | string | Unique response identifier (GUID) |
| Message | ChatMessage | The generated message content |
| FinishReason | FinishReason | Why generation stopped |
| Usage | UsageInfo | Token consumption metrics |
| Metadata | ResponseMetadata | Timing and provider info |
| Created | DateTimeOffset | When response was created |
| Model | string | Model identifier |
| Refusal | string? | Refusal explanation if declined |
| ContentFilterResults | IReadOnlyList? | Content moderation results |

#### FinishReason Values

| Value | Description | Common Cause |
|-------|-------------|--------------|
| Stop | Normal completion | Model finished naturally |
| Length | Max tokens reached | Response truncated |
| ToolCalls | Tool execution needed | Model requested tool call |
| ContentFilter | Moderation triggered | Content blocked |
| Error | Generation failed | Provider error |
| Cancelled | Request cancelled | User cancellation |

#### UsageInfo

Token consumption tracking:

```csharp
public record UsageInfo(
    int PromptTokens,
    int CompletionTokens,
    int? CachedTokens = null,
    int? ReasoningTokens = null)
{
    public int TotalTokens => PromptTokens + CompletionTokens;
    
    public static UsageInfo Empty => new(0, 0);
}
```

Usage tracking example:

```csharp
var usage1 = new UsageInfo(100, 50);
var usage2 = new UsageInfo(80, 30);
var total = usage1.Add(usage2);
// total.PromptTokens = 180, total.CompletionTokens = 80
```

### Configuration

Response types respect the following configuration from `.agent/config.yml`:

```yaml
model:
  default_provider: ollama
  timeout_seconds: 120
  
logging:
  include_response_content: false  # Truncates content in logs
  max_content_length: 200          # Maximum content in ToString()
```

### CLI Integration

Response data appears in CLI output:

```
$ acode ask "Explain recursion"
┌─────────────────────────────────────────────────────┐
│ Response                                             │
├─────────────────────────────────────────────────────┤
│ Recursion is a programming technique where...       │
│                                                     │
│ Tokens: 45 prompt, 128 completion (173 total)       │
│ Speed: 42.3 tok/s  │  Latency: 3.02s  │  TTFT: 89ms│
│ Model: llama3.2:8b │  Provider: ollama             │
└─────────────────────────────────────────────────────┘
```

### Working with Tool Call Responses

When the model requests tool execution:

```csharp
var response = await provider.CompleteAsync(request);

if (response.HasToolCalls)
{
    foreach (var toolCall in response.Message.ToolCalls!)
    {
        Console.WriteLine($"Tool: {toolCall.Name}");
        Console.WriteLine($"Args: {toolCall.Arguments}");
        
        // Execute tool and create result
        var result = await ExecuteToolAsync(toolCall);
        
        // Add result to conversation
        var toolMessage = ChatMessage.CreateToolResult(
            toolCall.Id,
            result
        );
        conversation.Add(toolMessage);
    }
    
    // Continue inference with tool results
    var continuation = await provider.CompleteAsync(
        request with { Messages = conversation.GetMessages() }
    );
}
```

### Handling Truncated Responses

When responses exceed max_tokens:

```csharp
if (response.IsTruncated)
{
    logger.LogWarning(
        "Response truncated at {Tokens} tokens. Consider increasing max_tokens.",
        response.Usage.CompletionTokens
    );
    
    // Option 1: Accept partial response
    // Option 2: Continue generation
    var continuation = await ContinueGeneration(response);
}
```

### Error Handling

Response error patterns:

```csharp
switch (response.FinishReason)
{
    case FinishReason.Stop:
        // Normal completion
        ProcessContent(response.Message.Content);
        break;
        
    case FinishReason.ToolCalls:
        // Execute requested tools
        await ExecuteToolCalls(response.Message.ToolCalls);
        break;
        
    case FinishReason.Length:
        // Response was truncated
        HandleTruncation(response);
        break;
        
    case FinishReason.ContentFilter:
        // Content was filtered
        LogFilterEvent(response.ContentFilterResults);
        throw new ContentFilteredException(response.Refusal);
        
    case FinishReason.Error:
        // Generation failed
        throw new InferenceException(response.Refusal);
        
    case FinishReason.Cancelled:
        // Request was cancelled
        throw new OperationCanceledException();
}
```

### Streaming Best Practices

Efficient streaming consumption:

```csharp
public async Task<ChatResponse> StreamWithProgressAsync(
    IAsyncEnumerable<ResponseDelta> stream,
    IProgress<string>? progress = null,
    CancellationToken cancellationToken = default)
{
    var accumulator = new DeltaAccumulator();
    var stopwatch = Stopwatch.StartNew();
    var firstToken = false;
    
    await foreach (var delta in stream.WithCancellation(cancellationToken))
    {
        if (!firstToken)
        {
            firstToken = true;
            logger.LogDebug("TTFT: {Ttft}ms", stopwatch.ElapsedMilliseconds);
        }
        
        accumulator.Append(delta);
        
        if (delta.ContentDelta is not null)
        {
            progress?.Report(delta.ContentDelta);
        }
    }
    
    var response = accumulator.Build();
    
    logger.LogDebug(
        "Streaming complete. {Tokens} tokens in {Duration}ms ({Rate:F1} tok/s)",
        response.Usage.CompletionTokens,
        stopwatch.ElapsedMilliseconds,
        response.Metadata.TokensPerSecond
    );
    
    return response;
}
```

### JSON Serialization

Response JSON format:

```json
{
  "id": "resp_abc123",
  "message": {
    "role": "assistant",
    "content": "Hello! How can I help you today?"
  },
  "finish_reason": "stop",
  "usage": {
    "prompt_tokens": 25,
    "completion_tokens": 12,
    "total_tokens": 37
  },
  "metadata": {
    "provider_id": "ollama",
    "model_id": "llama3.2:8b",
    "request_duration_seconds": 2.45,
    "time_to_first_token_seconds": 0.089,
    "tokens_per_second": 4.9
  },
  "created": "2024-01-15T10:30:00Z",
  "model": "llama3.2:8b"
}
```

### Troubleshooting

#### Response is Empty

**Symptoms:** Message.Content is null or empty

**Diagnosis:**
1. Check FinishReason - may be Error or ContentFilter
2. Check Refusal property for explanation
3. Verify prompt doesn't trigger content filters

#### Slow Token Generation

**Symptoms:** TokensPerSecond is very low (< 5)

**Diagnosis:**
1. Check model size vs available resources
2. Monitor GPU/CPU utilization
3. Review quantization settings
4. Check for memory pressure

#### Missing Usage Information

**Symptoms:** Usage shows zeros

**Diagnosis:**
1. Verify provider supports usage reporting
2. Check if streaming mode returns usage
3. Some models may not report tokens

#### Streaming Stalls

**Symptoms:** Stream stops delivering deltas

**Diagnosis:**
1. Check cancellation token status
2. Verify network connectivity to provider
3. Monitor provider process health
4. Check for resource exhaustion

---

## Acceptance Criteria

### ChatResponse Record

- [ ] AC-001: ChatResponse defined as immutable record
- [ ] AC-002: Id property exists and is required
- [ ] AC-003: Id validation requires non-empty string
- [ ] AC-004: Id defaults to GUID when using builder
- [ ] AC-005: Message property exists and is required
- [ ] AC-006: Message validation requires non-null
- [ ] AC-007: FinishReason property exists
- [ ] AC-008: FinishReason validation checks valid enum
- [ ] AC-009: Usage property exists and is required
- [ ] AC-010: Metadata property exists and is required
- [ ] AC-011: Created property exists
- [ ] AC-012: Created is DateTimeOffset UTC
- [ ] AC-013: Model property exists and is required
- [ ] AC-014: Refusal property exists (nullable)
- [ ] AC-015: ContentFilterResults property exists (nullable)
- [ ] AC-016: IsComplete computed property works
- [ ] AC-017: IsTruncated computed property works
- [ ] AC-018: HasToolCalls computed property works
- [ ] AC-019: Value equality by Id works
- [ ] AC-020: JSON serialization works
- [ ] AC-021: JSON deserialization works
- [ ] AC-022: Null properties omitted in JSON
- [ ] AC-023: Factory Success method works
- [ ] AC-024: Factory Truncated method works
- [ ] AC-025: Factory ToolCallsRequired method works
- [ ] AC-026: Factory Refused method works
- [ ] AC-027: Factory Error method works
- [ ] AC-028: Factory FromDelta method works

### FinishReason Enum

- [ ] AC-029: FinishReason enum defined
- [ ] AC-030: Stop value exists
- [ ] AC-031: Length value exists
- [ ] AC-032: ToolCalls value exists
- [ ] AC-033: ContentFilter value exists
- [ ] AC-034: Error value exists
- [ ] AC-035: Cancelled value exists
- [ ] AC-036: Serializes to snake_case strings
- [ ] AC-037: Deserializes case-insensitively
- [ ] AC-038: Maps from Ollama done_reason
- [ ] AC-039: Maps from vLLM finish_reason

### UsageInfo Record

- [ ] AC-040: UsageInfo defined as immutable record
- [ ] AC-041: PromptTokens property exists
- [ ] AC-042: PromptTokens validated non-negative
- [ ] AC-043: CompletionTokens property exists
- [ ] AC-044: CompletionTokens validated non-negative
- [ ] AC-045: TotalTokens computed correctly
- [ ] AC-046: CachedTokens optional property exists
- [ ] AC-047: CachedTokens validated when present
- [ ] AC-048: ReasoningTokens optional property exists
- [ ] AC-049: Empty static property returns zeros
- [ ] AC-050: Add method combines usage correctly
- [ ] AC-051: Value equality works
- [ ] AC-052: ToString format is correct
- [ ] AC-053: JSON serialization matches format

### ResponseMetadata Record

- [ ] AC-054: ResponseMetadata defined as immutable record
- [ ] AC-055: ProviderId property exists and required
- [ ] AC-056: ProviderId validated non-empty
- [ ] AC-057: ModelId property exists and required
- [ ] AC-058: ModelId validated non-empty
- [ ] AC-059: RequestDuration property exists
- [ ] AC-060: RequestDuration validated non-negative
- [ ] AC-061: TimeToFirstToken property exists (nullable)
- [ ] AC-062: TimeToFirstToken null for non-streaming
- [ ] AC-063: TokensPerSecond computed correctly
- [ ] AC-064: Extensions dictionary property exists
- [ ] AC-065: Extensions is read-only
- [ ] AC-066: Extensions preserves provider fields
- [ ] AC-067: JSON serialization works

### ResponseDelta Record

- [ ] AC-068: ResponseDelta defined as immutable record
- [ ] AC-069: Index property exists
- [ ] AC-070: ContentDelta property exists (nullable)
- [ ] AC-071: ToolCallDelta property exists (nullable)
- [ ] AC-072: FinishReason property exists (nullable)
- [ ] AC-073: Usage property exists (nullable)
- [ ] AC-074: IsComplete computed property works
- [ ] AC-075: Validation requires content or complete

### DeltaAccumulator

- [ ] AC-076: DeltaAccumulator class defined
- [ ] AC-077: Append method exists
- [ ] AC-078: ContentDelta strings concatenated
- [ ] AC-079: ToolCallDelta merged by index
- [ ] AC-080: FinishReason captured from last delta
- [ ] AC-081: Usage captured from last delta
- [ ] AC-082: Build method returns ChatResponse
- [ ] AC-083: Build throws if incomplete
- [ ] AC-084: Current property returns partial state
- [ ] AC-085: Thread-safe operation verified
- [ ] AC-086: StringBuilder used efficiently

### ResponseBuilder

- [ ] AC-087: ResponseBuilder class defined
- [ ] AC-088: WithId method exists
- [ ] AC-089: WithMessage method exists
- [ ] AC-090: WithFinishReason method exists
- [ ] AC-091: WithUsage method exists
- [ ] AC-092: WithMetadata method exists
- [ ] AC-093: WithRefusal method exists
- [ ] AC-094: Build method validates and creates
- [ ] AC-095: Auto-generates Id when not set
- [ ] AC-096: Auto-sets Created timestamp

### ContentFilterResult

- [ ] AC-097: ContentFilterResult record defined
- [ ] AC-098: Category enum property exists
- [ ] AC-099: Severity enum property exists
- [ ] AC-100: Filtered bool property exists
- [ ] AC-101: Reason optional property exists
- [ ] AC-102: JSON serialization works

### Performance

- [ ] AC-103: ChatResponse construction < 5μs
- [ ] AC-104: UsageInfo construction < 1μs
- [ ] AC-105: ResponseDelta construction < 1μs
- [ ] AC-106: DeltaAccumulator.Append < 10μs avg
- [ ] AC-107: DeltaAccumulator.Build < 100μs
- [ ] AC-108: JSON serialization < 1ms
- [ ] AC-109: JSON deserialization < 1ms
- [ ] AC-110: Memory allocation < 2KB base

### Security

- [ ] AC-111: Content treated as untrusted
- [ ] AC-112: ToString truncates content
- [ ] AC-113: No internal details exposed
- [ ] AC-114: Extensions is immutable
- [ ] AC-115: Error messages sanitized

### Documentation

- [ ] AC-116: XML documentation complete
- [ ] AC-117: Code examples provided
- [ ] AC-118: JSON format documented
- [ ] AC-119: Streaming patterns documented
- [ ] AC-120: Error handling documented

---

## Testing Requirements

### Unit Tests

```
Tests/Unit/Domain/Models/Responses/
├── ChatResponseTests.cs
│   ├── Should_Be_Immutable()
│   ├── Should_Require_Id()
│   ├── Should_Require_Message()
│   ├── Should_Validate_FinishReason()
│   ├── Should_Compute_IsComplete()
│   ├── Should_Compute_IsTruncated()
│   ├── Should_Compute_HasToolCalls()
│   ├── Should_Implement_Value_Equality()
│   ├── Should_Serialize_To_Json()
│   ├── Should_Deserialize_From_Json()
│   ├── Should_Omit_Null_Properties()
│   ├── Success_Factory_Should_Work()
│   ├── Truncated_Factory_Should_Work()
│   ├── ToolCallsRequired_Factory_Should_Work()
│   ├── Refused_Factory_Should_Work()
│   └── Error_Factory_Should_Work()
│
├── FinishReasonTests.cs
│   ├── Should_Have_All_Values()
│   ├── Should_Serialize_To_SnakeCase()
│   ├── Should_Deserialize_CaseInsensitive()
│   ├── Should_Map_From_Ollama()
│   └── Should_Map_From_Vllm()
│
├── UsageInfoTests.cs
│   ├── Should_Compute_TotalTokens()
│   ├── Should_Validate_NonNegative()
│   ├── Should_Add_Usage()
│   ├── Empty_Should_Return_Zeros()
│   ├── Should_Serialize_To_Json()
│   └── Should_Have_Correct_ToString()
│
├── ResponseMetadataTests.cs
│   ├── Should_Require_ProviderId()
│   ├── Should_Require_ModelId()
│   ├── Should_Compute_TokensPerSecond()
│   ├── Should_Allow_Null_TTFT()
│   ├── Should_Preserve_Extensions()
│   └── Should_Be_Immutable()
│
├── ResponseDeltaTests.cs
│   ├── Should_Require_Content_Or_Complete()
│   ├── Should_Compute_IsComplete()
│   ├── Should_Allow_ToolCallDelta()
│   └── Should_Have_Index()
│
├── DeltaAccumulatorTests.cs
│   ├── Should_Concatenate_Content()
│   ├── Should_Merge_ToolCalls_By_Index()
│   ├── Should_Capture_FinishReason()
│   ├── Should_Capture_Usage()
│   ├── Build_Should_Return_Response()
│   ├── Build_Should_Throw_If_Incomplete()
│   ├── Should_Be_ThreadSafe()
│   └── Current_Should_Return_Partial()
│
└── ResponseBuilderTests.cs
    ├── Should_Build_Valid_Response()
    ├── Should_AutoGenerate_Id()
    ├── Should_AutoSet_Created()
    ├── Should_Validate_Required_Fields()
    └── Should_Support_Fluent_API()
```

### Integration Tests

```
Tests/Integration/Models/Responses/
├── ResponseSerializationTests.cs
│   ├── Should_Match_Ollama_Format()
│   ├── Should_Match_Vllm_Format()
│   ├── Should_Handle_Extensions()
│   └── Should_Roundtrip_All_Types()
│
└── StreamingResponseTests.cs
    ├── Should_Accumulate_Deltas()
    ├── Should_Handle_Cancellation()
    └── Should_Propagate_Errors()
```

### End-to-End Tests

```
Tests/E2E/Responses/
├── ResponseProcessingTests.cs
│   ├── Should_Process_Complete_Response()
│   ├── Should_Handle_Truncated_Response()
│   ├── Should_Handle_ToolCall_Response()
│   └── Should_Handle_Error_Response()
```

### Performance Tests

```
Tests/Performance/Models/Responses/
├── ResponseBenchmarks.cs
│   ├── Benchmark_ChatResponse_Construction()
│   ├── Benchmark_UsageInfo_Operations()
│   ├── Benchmark_Serialization()
│   ├── Benchmark_Deserialization()
│   ├── Benchmark_DeltaAccumulator_Append()
│   └── Benchmark_DeltaAccumulator_Build()
```

---

## User Verification Steps

### Scenario 1: Create Success Response

1. Create UsageInfo with 100 prompt, 50 completion tokens
2. Create ResponseMetadata with provider "ollama"
3. Use ChatResponse.Success factory
4. Verify FinishReason is Stop
5. Verify IsComplete is true

### Scenario 2: Create Truncated Response

1. Use ChatResponse.Truncated factory
2. Verify FinishReason is Length
3. Verify IsTruncated is true

### Scenario 3: Create ToolCalls Response

1. Create response with ToolCalls in message
2. Use ChatResponse.ToolCallsRequired factory
3. Verify HasToolCalls is true

### Scenario 4: Accumulate Streaming Deltas

1. Create DeltaAccumulator
2. Append 5 content deltas
3. Append final delta with FinishReason
4. Call Build()
5. Verify content is concatenated

### Scenario 5: Handle Error Response

1. Create ChatResponse.Error with message
2. Verify FinishReason is Error
3. Verify Refusal contains error message

### Scenario 6: Serialize Response to JSON

1. Create complete ChatResponse
2. Serialize to JSON
3. Verify snake_case property names
4. Verify null properties omitted
5. Deserialize back
6. Verify equality

### Scenario 7: Usage Arithmetic

1. Create two UsageInfo instances
2. Add them together
3. Verify PromptTokens summed
4. Verify CompletionTokens summed

### Scenario 8: ResponseBuilder Usage

1. Create ResponseBuilder
2. Set all properties via fluent API
3. Call Build()
4. Verify all properties set correctly

### Scenario 9: ThreadSafe Accumulator

1. Create DeltaAccumulator
2. Append deltas from multiple threads
3. Verify no data corruption
4. Verify Build() returns valid response

### Scenario 10: Provider Extension Preservation

1. Create ResponseMetadata with Extensions
2. Serialize to JSON
3. Deserialize
4. Verify Extensions preserved

---

## Implementation Prompt

### File Structure

```
src/AgenticCoder.Domain/Models/Responses/
├── ChatResponse.cs
├── FinishReason.cs
├── UsageInfo.cs
├── ResponseMetadata.cs
├── ResponseDelta.cs
├── DeltaAccumulator.cs
├── ResponseBuilder.cs
├── ContentFilterResult.cs
└── Serialization/
    └── ResponseJsonContext.cs
```

### ChatResponse Implementation

```csharp
namespace AgenticCoder.Domain.Models;

public sealed record ChatResponse
{
    public required string Id { get; init; }
    public required ChatMessage Message { get; init; }
    public required FinishReason FinishReason { get; init; }
    public required UsageInfo Usage { get; init; }
    public required ResponseMetadata Metadata { get; init; }
    public required DateTimeOffset Created { get; init; }
    public required string Model { get; init; }
    
    [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
    public string? Refusal { get; init; }
    
    [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
    public IReadOnlyList<ContentFilterResult>? ContentFilterResults { get; init; }
    
    public bool IsComplete => FinishReason == FinishReason.Stop;
    public bool IsTruncated => FinishReason == FinishReason.Length;
    public bool HasToolCalls => Message.ToolCalls is { Count: > 0 };
    
    public static ChatResponse Success(
        ChatMessage message,
        UsageInfo usage,
        string model,
        ResponseMetadata? metadata = null) => new()
    {
        Id = Guid.NewGuid().ToString(),
        Message = message,
        FinishReason = FinishReason.Stop,
        Usage = usage,
        Metadata = metadata ?? CreateDefaultMetadata(model),
        Created = DateTimeOffset.UtcNow,
        Model = model
    };
    
    // Additional factory methods...
}
```

### FinishReason Implementation

```csharp
namespace AgenticCoder.Domain.Models;

[JsonConverter(typeof(JsonStringEnumConverter<FinishReason>))]
public enum FinishReason
{
    [JsonPropertyName("stop")]
    Stop = 0,
    
    [JsonPropertyName("length")]
    Length = 1,
    
    [JsonPropertyName("tool_calls")]
    ToolCalls = 2,
    
    [JsonPropertyName("content_filter")]
    ContentFilter = 3,
    
    [JsonPropertyName("error")]
    Error = 4,
    
    [JsonPropertyName("cancelled")]
    Cancelled = 5
}
```

### UsageInfo Implementation

```csharp
namespace AgenticCoder.Domain.Models;

public sealed record UsageInfo(
    [property: JsonPropertyName("prompt_tokens")]
    int PromptTokens,
    
    [property: JsonPropertyName("completion_tokens")]
    int CompletionTokens,
    
    [property: JsonPropertyName("cached_tokens")]
    [property: JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
    int? CachedTokens = null,
    
    [property: JsonPropertyName("reasoning_tokens")]
    [property: JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
    int? ReasoningTokens = null)
{
    [JsonPropertyName("total_tokens")]
    public int TotalTokens => PromptTokens + CompletionTokens;
    
    public static UsageInfo Empty => new(0, 0);
    
    public UsageInfo Add(UsageInfo other) => new(
        PromptTokens + other.PromptTokens,
        CompletionTokens + other.CompletionTokens,
        (CachedTokens ?? 0) + (other.CachedTokens ?? 0) is var c and > 0 ? c : null,
        (ReasoningTokens ?? 0) + (other.ReasoningTokens ?? 0) is var r and > 0 ? r : null
    );
    
    public override string ToString() =>
        $"Prompt: {PromptTokens}, Completion: {CompletionTokens}, Total: {TotalTokens}";
}
```

### Implementation Checklist

1. [ ] Define FinishReason enum with JSON attributes
2. [ ] Define UsageInfo record with validation
3. [ ] Implement UsageInfo.Add method
4. [ ] Define ResponseMetadata record
5. [ ] Implement TokensPerSecond computation
6. [ ] Define ResponseDelta record
7. [ ] Define DeltaAccumulator class
8. [ ] Implement thread-safe Append
9. [ ] Implement Build with validation
10. [ ] Define ResponseBuilder class
11. [ ] Implement fluent API methods
12. [ ] Define ChatResponse record
13. [ ] Implement factory methods
14. [ ] Define ContentFilterResult
15. [ ] Add JSON source generator context
16. [ ] Write unit tests
17. [ ] Write integration tests
18. [ ] Add XML documentation

### Error Codes

| Code | Message |
|------|---------|
| ACODE-RSP-001 | Response ID cannot be empty |
| ACODE-RSP-002 | Response message cannot be null |
| ACODE-RSP-003 | Invalid finish reason value |
| ACODE-RSP-004 | Token count cannot be negative |
| ACODE-RSP-005 | Provider ID cannot be empty |
| ACODE-RSP-006 | Model ID cannot be empty |
| ACODE-RSP-007 | Request duration cannot be negative |
| ACODE-RSP-008 | Cannot build incomplete response |
| ACODE-RSP-009 | Delta must have content or be complete |
| ACODE-RSP-010 | Accumulator received out-of-order delta |

### Dependencies

- Task 004 (IModelProvider returns ChatResponse)
- Task 004.a (Message types used in responses)
- System.Text.Json for serialization

### Verification Command

```bash
dotnet test --filter "FullyQualifiedName~Responses"
```

---

**End of Task 004.b Specification**
